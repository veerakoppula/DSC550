{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3e5177",
   "metadata": {},
   "source": [
    "# Assignment: 3.2 Exercise: Sentiment Analysis and Preprocessing Text\n",
    " \n",
    " Download the labeled training dataset from this link: Bag of Words Meets Bags of Popcorn. \n",
    "\n",
    "**Part 1: Using the TextBlob Sentiment Analyzer**\n",
    "\n",
    "<br>1. Import the movie review data as a data frame and ensure that the data is loaded properly.\n",
    "<br>2. How many of each positive and negative reviews are there?\n",
    "<br>3. Use TextBlob to classify each movie review as positive or negative. Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment.\n",
    "<br>4. Check the accuracy of this model. Is this model better than random guessing?\n",
    "<br>5. For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4).\n",
    "\n",
    "**Part 2: Prepping Text for a Custom Model**\n",
    "\n",
    "If you want to run your own model to classify text, it needs to be in proper form to do so. The following steps will outline a procedure to do this on the movie reviews text.\n",
    "\n",
    "<br>1. Convert all text to lowercase letters.\n",
    "<br>2. Remove punctuation and special characters from the text.\n",
    "<br>3. Remove stop words.\n",
    "<br>4. Apply NLTK’s PorterStemmer.\n",
    "<br>5. Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as the number of rows in your original data frame.\n",
    "<br>6. Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab823ba",
   "metadata": {},
   "source": [
    "**Part 1: Using the TextBlob Sentiment Analyzer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8120737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preloading necessary packages\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re as re\n",
    "from textblob import TextBlob\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4e6d8e",
   "metadata": {},
   "source": [
    "###### 1. Import the movie review data as a data frame and ensure that the data is loaded properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b0ba189",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data into data frame\n",
    "train = pd.read_csv('labeledTrainData.tsv.zip', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5ab37a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking train data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b1ba2",
   "metadata": {},
   "source": [
    "**Data frame contents**\n",
    "\n",
    "File descriptions:\n",
    "labeledTrainData - The labeled training set. The file is tab-delimited and has a header row followed by 25,000 rows containing an id, sentiment, and text for each review.  \n",
    "\n",
    "Data fields:\n",
    "<br>id - Unique ID of each review\n",
    "<br>sentiment - Sentiment of the review; 1 for positive reviews and 0 for negative reviews\n",
    "<br>review - Text of the review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed2708",
   "metadata": {},
   "source": [
    "###### 2. How many of each positive and negative reviews are there? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35a3f3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the data set with positive reviews in dataset : 12500\n",
      "Number of rows in the data set with Negative reviews in dataset : 12500\n"
     ]
    }
   ],
   "source": [
    "#Checking coungs of positive and negative reviews\n",
    "print(\"Number of rows in the data set with positive reviews in dataset :\", sum(train['sentiment'] == 1))\n",
    "print(\"Number of rows in the data set with Negative reviews in dataset :\", sum(train['sentiment'] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeeb2f2",
   "metadata": {},
   "source": [
    "###### 3. Use TextBlob to classify each movie review as positive or negative. Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd50b41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column in data frame with TextBlob Sentiment analysis\n",
    "train['sentimentTB'] = train['review'].apply(lambda review: TextBlob(review).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e81af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the data set with positive reviews in dataset per textBlob Analysis : 19017\n",
      "Number of rows in the data set with Negative reviews in dataset per textBlob Analysis : 5983\n"
     ]
    }
   ],
   "source": [
    "#Calculating positive and negative review sentiment analysis count by TextBlob\n",
    "print(\"Number of rows in the data set with positive reviews in dataset per textBlob Analysis :\", sum(train['sentimentTB'] >= 0))\n",
    "print(\"Number of rows in the data set with Negative reviews in dataset per textBlob Analysis :\", sum(train['sentimentTB'] < 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a118687",
   "metadata": {},
   "source": [
    "###### 4. Check the accuracy of this model. Is this model better than random guessing? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "230f0737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate positive sentiment prediction by textBlob : 11824\n",
      "Accurate negative sentiment prediction by textBlob : 5307\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy of textBlob where labelled test data and textBlob preduction for sentiment are matching\n",
    "print(\"Accurate positive sentiment prediction by textBlob :\", sum((train['sentiment'] > 0) & (train['sentimentTB'] >= 0)))\n",
    "print(\"Accurate negative sentiment prediction by textBlob :\", sum((train['sentiment'] <= 0) & (train['sentimentTB'] < 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1f4b2",
   "metadata": {},
   "source": [
    "Total number of agreements by textBlob:  11824+5307 = 18483\n",
    "<br>Total number of samples: 25000\n",
    "<br> Accuracy of textBob = (18483/25000)*100 = 73.932%\n",
    "<br>Accuracy of textBob model is about 73.932%. This is definitely better than random guessing as it would be a 50% accurate model with either yes or no. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3167e9da",
   "metadata": {},
   "source": [
    "###### 5. For up to five points extra credit, use another prebuilt text sentiment analyzer, e.g., VADER, and repeat steps (3) and (4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f35f4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing vader module\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f66b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a column with Vader sentiment analysis\n",
    "pdanalyzer = SentimentIntensityAnalyzer()\n",
    "train['sentimentV'] = train['review'].apply(lambda review: pdanalyzer.polarity_scores(review).get('compound'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85e0a638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the data set with positive reviews in dataset per textBlob Analysis : 16611\n",
      "Number of rows in the data set with Negative reviews in dataset per textBlob Analysis : 8389\n"
     ]
    }
   ],
   "source": [
    "#Calculating positive and negative review sentiment analysis count by Vader\n",
    "print(\"Number of rows in the data set with positive reviews in dataset per textBlob Analysis :\", sum(train['sentimentV'] >= 0))\n",
    "print(\"Number of rows in the data set with Negative reviews in dataset per textBlob Analysis :\", sum(train['sentimentV'] < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96958956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate positive sentiment prediction by textBlob : 10731\n",
      "Accurate negative sentiment prediction by textBlob : 6620\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy of textBlob where labelled test data and VADER preduction for sentiment are matching\n",
    "print(\"Accurate positive sentiment prediction by textBlob :\", sum((train['sentiment'] > 0) & (train['sentimentV'] >= 0)))\n",
    "print(\"Accurate negative sentiment prediction by textBlob :\", sum((train['sentiment'] <= 0) & (train['sentimentV'] < 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785dd240",
   "metadata": {},
   "source": [
    "Total number of agreements by VADER:  10731+6620 = 17351\n",
    "<br>Total number of samples: 25000\n",
    "<br> Accuracy of VADER = (17351/25000)*100 = 69.404%\n",
    "<br>Accuracy of VADER model is about 68.524%. This is definitely better than random guessing as it would be a 50% accurate model with either yes or no. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fda13a",
   "metadata": {},
   "source": [
    "**Part 2: Prepping Text for a Custom Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a42d9b",
   "metadata": {},
   "source": [
    "###### Clean Data\n",
    "<br>1. Convert all text to lowercase letters. \n",
    "<br>2. Remove punctuation and special characters from the text. \n",
    "<br>3. Remove stop words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92dba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating function to clean text\n",
    "def clean_text(text):\n",
    "    text = BeautifulSoup(text).get_text() #beautifying text\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text) # clean the html charecters (non text)\n",
    "    words = letters_only.lower().split()   # convert to lower text                        \n",
    "    stops = set(stopwords.words(\"english\")) # setting stop words to remove                  \n",
    "    main_words = [w for w in words if not w in stops]   \n",
    "    return( \" \".join( main_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21cc0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying clean function on the data frame and creating a new column with clean text\n",
    "train['clean_review'] = train['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53e7146",
   "metadata": {},
   "source": [
    "###### 4. Apply NLTK’s PorterStemmer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02510e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import these modules\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "798d68e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying porterstemmer on clean_review\n",
    "ps = PorterStemmer()\n",
    "train['clean_review'] = train['clean_review'].apply(lambda review: ps.stem(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "066961cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go', 'immediately', 'rent', 'movie', 'bottom', 'shelf', 'local', 'video', 'store', 'covered', 'dust', 'one', 'touched', 'years', 'may', 'even', 'special', 'worth', 'ten', 'bucks', 'swear', 'buy', 'many', 'films', 'compare', 'celluloid', 'version', 'goo', 'forms', 'bottom', 'trash', 'years', 'yes', 'gave', 'really', 'deserves', 'much', 'lower', 'scales', 'designed', 'stuff', 'like', 'mind']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize # importing word_tokenize\n",
    "#extracting and prinitng tokenized values sample\n",
    "corpora = train['clean_review'].values\n",
    "tokenized = [word_tokenize(corpus) for corpus in corpora]\n",
    "\n",
    "print(tokenized[2222])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19e6e4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 6)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of train data frame\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c44d39",
   "metadata": {},
   "source": [
    "###### 5. Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as the number of rows in your original data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7c8c2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating bag_of_words matrix from clean review\n",
    "count = CountVectorizer()\n",
    "bag_of_words = count.fit_transform(train['clean_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34401f4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x75529 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2446144 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words #Size of bag_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd4887",
   "metadata": {},
   "source": [
    "Above shows that the number of rows is still 25000 (same as original dataframe train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb04f2ec",
   "metadata": {},
   "source": [
    "###### 6. Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79a30fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 75529)\n"
     ]
    }
   ],
   "source": [
    "# Import tf-idf encoding from sklearn library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Define some hiperparameters of encoded\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Create the training set with the words encoded as features of the reviews\n",
    "train_data_features = vectorizer.fit_transform(train['clean_review'])\n",
    "\n",
    "print(train_data_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d396f3c",
   "metadata": {},
   "source": [
    "As above shows the shape (25000, 75529) matches the bag_of_words shape from above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a10e0a",
   "metadata": {},
   "source": [
    "###### Applying logistics regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad9b6312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the logistic regression model from sklearn \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the model\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs',\n",
    "                            multi_class='multinomial')\n",
    "# Train model\n",
    "model.fit(train_data_features, train['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4f55ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Testing the model against entire train data from origianl train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb2d7a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 3)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_sentiment</th>\n",
       "      <th>sentiment_custom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"3630_4\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"9495_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  original_sentiment  sentiment_custom\n",
       "0  \"5814_8\"                   1                 1\n",
       "1  \"2381_9\"                   1                 1\n",
       "2  \"7759_3\"                   0                 0\n",
       "3  \"3630_4\"                   0                 0\n",
       "4  \"9495_8\"                   1                 0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test data\n",
    "test = pd.read_csv(\"labeledTrainData.tsv.zip\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "print(test.shape)\n",
    "\n",
    "# Clean the text of all reviews in the training set\n",
    "print(\"Cleaning and parsing the test set movie reviews...\\n\")\n",
    "test['clean_review'] = test['review'].apply(clean_text)\n",
    "\n",
    "# Create the test set with the words encoded as features of the reviews\n",
    "test_data_features = vectorizer.transform(test['clean_review'])\n",
    "\n",
    "\n",
    "# Use the logistic regression model to make sentiment label predictions\n",
    "result = model.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and a \"sentiment\" column\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"],\"original_sentiment\":test[\"sentiment\"] ,\"sentiment_custom\":result})\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "321c5d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the data set with positive reviews in dataset per custom model : 12611\n",
      "Number of rows in the data set with negative reviews in dataset per custom model : 12389\n"
     ]
    }
   ],
   "source": [
    "#Calculating positive and negative review sentiment analysis count by my custom model\n",
    "print(\"Number of rows in the data set with positive reviews in dataset per custom model :\", sum(output['sentiment_custom'] == 1))\n",
    "print(\"Number of rows in the data set with negative reviews in dataset per custom model :\", sum(output['sentiment_custom'] == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "776ecf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accurate positive sentiment prediction by custom model : 11997\n",
      "Accurate negative sentiment prediction by custom model : 11886\n"
     ]
    }
   ],
   "source": [
    "#Calculating Accuracy of custom model where labelled test data and VADER preduction for sentiment are matching\n",
    "print(\"Accurate positive sentiment prediction by custom model :\", sum((output['original_sentiment'] == 1) & (output['sentiment_custom'] == 1)))\n",
    "print(\"Accurate negative sentiment prediction by custom model :\", sum((output['original_sentiment'] == 0) & (output['sentiment_custom'] == 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a3136d",
   "metadata": {},
   "source": [
    "Total number of agreements by custom model:  11997+11886 = 23883\n",
    "<br>Total number of samples: 25000\n",
    "<br> Accuracy of VADER = (17351/25000)*100 = 95.532%\n",
    "<br>Accuracy of VADER model is about 95.532%. This is definitely better than random guessing as it would be a 50% accurate model with either yes or no. \n",
    "\n",
    "Although the accuracy of the model is very high, it could be a resultant of train and test set being exactly same.\n",
    "This could be a situation of overfitting of the custom model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd6cfb5",
   "metadata": {},
   "source": [
    "###### performing prediction on test data in Kaggle from the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a2cfe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 2)\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"12311_10\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"8348_2\"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"5828_4\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"7186_2\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"12128_7\"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  sentiment\n",
       "0  \"12311_10\"          1\n",
       "1    \"8348_2\"          0\n",
       "2    \"5828_4\"          1\n",
       "3    \"7186_2\"          1\n",
       "4   \"12128_7\"          1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the test data\n",
    "test2 = pd.read_csv(\"testData.tsv.zip\", header=0, delimiter=\"\\t\", \\\n",
    "                   quoting=3 )\n",
    "print(test2.shape)\n",
    "\n",
    "\n",
    "# Clean the text of all reviews in the training set\n",
    "print(\"Cleaning and parsing the test set movie reviews...\\n\")\n",
    "test2['clean_review'] = test2['review'].apply(clean_text)\n",
    "\n",
    "# Create the test set with the words encoded as features of the reviews\n",
    "test_data_features = vectorizer.transform(test2['clean_review'])\n",
    "\n",
    "\n",
    "# Use the logistic regression model to make sentiment label predictions\n",
    "result = model.predict(test_data_features)\n",
    "\n",
    "# Copy the results to a pandas dataframe with an \"id\" column and a \"sentiment\" column\n",
    "output_test = pd.DataFrame( data={\"id\":test2[\"id\"],\"sentiment\":result})\n",
    "output_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac84b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test.to_csv(\"test_result.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfe4ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
